{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input('enter your text: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  139,  9485,  3775,   317,  5858,   108,  3655,   111,   176,  1392,\n",
       "          1539,   111,   109,   698,  1397,   111,  1180, 10666,  3401,   114,\n",
       "          4749,  4668,   115,   109,  8695,  5199, 20911, 27202,   109,  2709,\n",
       "           503,   107,   139,  3121,  8924,   141,   109, 15500, 12421,   113,\n",
       "          1086,   111,   109,  8252, 38325, 12421,   195, 16849,   115,   297,\n",
       "           141,  4958,  3941,   111,   203,   207,   115,   109,  1397,   503,\n",
       "           107,  2595,  5858,   111,  3655,  2417,   120,   109,   698, 10666,\n",
       "           108,   330,  2107,   191,   897, 17928,   108,  1814,   108,  4148,\n",
       "           191, 25208,   191, 23776,   108, 86460,   108,  7697,   108, 29962,\n",
       "           191, 31908,   108,  6320,   108, 11235, 13339,   107,   111, 18304,\n",
       "           108,   138,   207,   110, 48940,  5344,   112, 13457,   183,   107,\n",
       "         12410, 47412,  5344,   117,   114,   515,   113,  4958,  3941,   120,\n",
       "         23153,   135,  1352,   111,  1055,   112,  2093,  1449,   177,  1158,\n",
       "           111,  2580,   659,   107,   412,   180,  2304,   127,   109,  3655,\n",
       "           111,  5858,  4304,   113,   152,   125,   123,   208,   114,  4609,\n",
       "           113, 20028,  3146,   107,   125,  3047,   114,  3598,  1855,   120,\n",
       "         15551,   109,  1140,   107,   125, 23937,   109,   645,  5577,   190,\n",
       "          9327,  1064, 12943,   151,  5855,   114,  4435,   118,   114,  6604,\n",
       "          4860,   896,  2754, 26053,   111,  6755,   107,   222,  2286,   108,\n",
       "           114,  4435,  2893,   107,  3516,   108,   125,  1049,   118,   114,\n",
       "          1785,   467,   108,   114,  8942,   113,   290,  1529,  1785,   690,\n",
       "           118,   109,   896,   107,  5563,   108,   114,  1407,  2893,   744,\n",
       "          4772,   108,  2754,   146,   209,   114,   185, 10650,  3528,   113,\n",
       "           546,   817,   483,   155,   163,   114,  5645, 52010,  5936,   107,\n",
       "           139,  3977,   540,  3498,   114,   827,  1785,  1986,   185, 51835,\n",
       "          1879,   111,  6755,  2044,   429,   135,   109,  1777,   424,   108,\n",
       "           561,   115,   561,  1181,  3516,   108,   124,   114,  1352,   121,\n",
       "           497,   121, 15006,  1258,   108,   125, 23937,   219,   989,   190,\n",
       "           114,  1076, 11559,   185, 71776,   227,   151,   185, 75531,  8207,\n",
       "          1397,  1785,   113, 53396, 28569,   130, 26053,  2044,   828,   109,\n",
       "          1777,   108,   616,  1039,   523,   108,  3331,  1796, 11181, 30231,\n",
       "           109,  1236,   108,  3930,  1190,  4377,   108, 12060,  2011,   108,\n",
       "           896,  6036,  1181,  3440,   114,  1960,   678,   108,   114,  4601,\n",
       "         12723,   545,  2893,   107,   168,  2375,   114,   110,   116,   261,\n",
       "         41539, 38932,  1590,  2044,   124,   109,  1777,   107,   125,   116,\n",
       "           126, 53396, 28569,   152,   125,   116,   126, 26053,   152,   168,\n",
       "           123,   116,   514,   112,   416,   107,   125,  1159,   112,   535,\n",
       "           161,   282,   749,   115,   295,   113, 28569,   123,   116,   188,\n",
       "           118,   546,   108,   111,   115,  2286,   108,   125,   123,   261,\n",
       "           266,   109,  9333,   107,   125,   239,   133,   114,  1218,   805,\n",
       "          6201,   124,   161,  4305,   120,   125,   137,   535,   112,   109,\n",
       "          4435,   111,  1785,   467,   108,   111,   125,   123,   208,   210,\n",
       "           124,   161,   230,   112, 11291,   114,   613,   896, 11692,   647,\n",
       "          1851,   113,   172, 53396, 28569,   130, 26053,   107,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.generate(**tokens, max_length= 200, min_length= 100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   222,   150,   679,   113,  3439,   135,  2636,   121,  5339,\n",
       "          8755,   108, 23781,   111,  2678, 11626,   121, 81522, 17083, 51754,\n",
       "           978,   134,   180,   123,   116,   134,   109,   773,   113,   109,\n",
       "         37949,   116,   123,  5100,   111,   180,   123,   116,   134,   109,\n",
       "           773,   113,   109,  8252, 38325, 12421,   123,   116,  7581,   122,\n",
       "          5090, 10666,   204,   626,   118, 37208,  1180,   111,   896,   201,\n",
       "           108,   111,   180,   123,   116,   134,   109,   773,   113,   109,\n",
       "         37949,   116,   123,  5100,   111,   180,   123,   116,   134,   109,\n",
       "           773,   113,   109,  8252, 38325, 12421,   123,   116,  7581,   122,\n",
       "          5090, 10666,   204,   626,   118, 37208,  1180,   111,   896,   201,\n",
       "           108,   111,   180,   123,   116,   134,   109,   773,   113,   109,\n",
       "         37949,   116,   123,  5100,   111,   180,   123,   116,   134,   109,\n",
       "           773,   113,   109,  8252, 38325, 12421,   123,   116,  7581,   122,\n",
       "          5090, 10666,   204,   626,   118, 37208,  1180,   111,   896,   201,\n",
       "           108,   111,   180,   123,   116,   134,   109,   773,   113,   109,\n",
       "         37949,   116,   123,  5100,   111,   180,   123,   116,   134,   109,\n",
       "           773,   113,   109,  8252, 38325, 12421,   123,   116,  7581,   122,\n",
       "          5090, 10666,   204,   626,   118, 37208,  1180,   111,   896,   201,\n",
       "           108,   111,   180,   123,   116,   134,   109,   773,   113,   109,\n",
       "         37949,   116,   123,  5100,   111,   180,   123,   116,   134,     1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In our series of letters from African-American journalists, novelist and writer Ta-Nehisi Coates looks at whatâ€™s at the heart of the screenwritersâ€™ strike and whatâ€™s at the heart of the Screen Actors Guildâ€™s dispute with Hollywood studios over pay for scripted TV and film work, and whatâ€™s at the heart of the screenwritersâ€™ strike and whatâ€™s at the heart of the Screen Actors Guildâ€™s dispute with Hollywood studios over pay for scripted TV and film work, and whatâ€™s at the heart of the screenwritersâ€™ strike and whatâ€™s at the heart of the Screen Actors Guildâ€™s dispute with Hollywood studios over pay for scripted TV and film work, and whatâ€™s at the heart of the screenwritersâ€™ strike and whatâ€™s at the heart of the Screen Actors Guildâ€™s dispute with Hollywood studios over pay for scripted TV and film work, and whatâ€™s at the heart of the screenwritersâ€™ strike and whatâ€™s at'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(summary[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
