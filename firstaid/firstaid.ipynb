{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Leinad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leinad\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"intents.json\") as file:\n",
    "\tdata = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "labels = []\n",
    "docs_x = []\n",
    "docs_y = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "\tfor pattern in intent[\"patterns\"]:\n",
    "\t\twrds = nltk.word_tokenize(pattern)\n",
    "\t\twords.extend(wrds)\n",
    "\t\tdocs_x.append(wrds)\n",
    "\t\tdocs_y.append(intent[\"tag\"])\n",
    "\n",
    "\tif intent[\"tag\"] not in labels:\n",
    "\t\tlabels.append(intent[\"tag\"])\n",
    "\n",
    "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "labels = sorted(labels)\n",
    "\n",
    "\n",
    "training = []\n",
    "output = []\n",
    "\n",
    "out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "for x, doc in enumerate(docs_x):\n",
    "\tbag = []\n",
    "\n",
    "\twrds = [stemmer.stem(w) for w in doc]\n",
    "\n",
    "\tfor w in words:\n",
    "\t\tif w in wrds:\n",
    "\t\t\tbag.append(1)\n",
    "\t\telse:\n",
    "\t\t\tbag.append(0)\n",
    "\toutput_row = out_empty[:]\n",
    "\toutput_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "\ttraining.append(bag)\n",
    "\toutput.append(output_row)\n",
    "\n",
    "training = numpy.array(training)\n",
    "output = numpy.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abdonominal Pain',\n",
       " 'Abrasions',\n",
       " 'Broken Toe',\n",
       " 'Bruises',\n",
       " 'CPR',\n",
       " 'Chemical Burn',\n",
       " 'Choking',\n",
       " 'Cold',\n",
       " 'Cough',\n",
       " 'Cuts',\n",
       " 'Diarrhea',\n",
       " 'Drowning',\n",
       " 'Eye Injury',\n",
       " 'Fainting',\n",
       " 'Fever',\n",
       " 'Fracture',\n",
       " 'Frost bite',\n",
       " 'Gastrointestinal problems',\n",
       " 'Head Injury',\n",
       " 'Headache',\n",
       " 'Heat Exhaustion',\n",
       " 'Heat Stroke',\n",
       " 'Insect Bites',\n",
       " 'Nasal Congestion',\n",
       " 'Normal Bleeding',\n",
       " 'Poison',\n",
       " 'Pulled Muscle',\n",
       " 'Rash',\n",
       " 'Rectal bleeding',\n",
       " 'Skin problems',\n",
       " 'Sore Throat',\n",
       " 'Splinter',\n",
       " 'Sprains',\n",
       " 'Strains',\n",
       " 'Sun Burn',\n",
       " 'Teeth',\n",
       " 'Testicle Pain',\n",
       " 'Vertigo',\n",
       " 'Wound',\n",
       " 'animal bite',\n",
       " 'nose bleed',\n",
       " 'seizure',\n",
       " 'snake bite',\n",
       " 'stings']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leinad\\AppData\\Roaming\\Python\\Python311\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from c:\\Users\\Leinad\\Documents\\Tech_Villain\\Leinadpython\\firstaid\\model.tflearn\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\tmodel.load(\"model.tflearn\")\n",
    "except:\n",
    "\tmodel = tflearn.DNN(net)\n",
    "\tmodel.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "\tmodel.save(\"model.tflearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bag_of_words(s,words):\n",
    "\tbag = [0 for _ in range(len(words))]\n",
    "\n",
    "\n",
    "\ts_words = nltk.word_tokenize(s)\n",
    "\ts_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "\tfor se in s_words:\n",
    "\t\tfor i, w in enumerate(words):\n",
    "\t\t\tif w == se:\n",
    "\t\t\t\tbag[i] = 1\n",
    "\n",
    "\treturn numpy.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "\tprint(\"Start Talking with the bot(type quit to stop!\")\n",
    "\twhile True:\n",
    "\t\tinp = input(\"You: \")\n",
    "\t\tif inp.lower() == \"quit\":\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tresults = model.predict([bag_of_words(inp,words)])[0]\n",
    "\t\tresults_index = numpy.argmax(results)\n",
    "\t\ttag = labels[results_index]\n",
    "\n",
    "\t\tif results[results_index] > 0.5:\n",
    "\t\t\tfor tg in data[\"intents\"]:\n",
    "\t\t\t\tif tg['tag'] == tag:\n",
    "\t\t\t\t\tresponses = tg['responses']\t\n",
    "\t\t\tprint(random.choice(responses))\n",
    "\t\t\tprint(\"\\n\")\n",
    "\t\telse:\n",
    "\t\t\tprint(\"I didnt get that, try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Talking with the bot(type quit to stop!\n",
      "To treat a fever at home:\n",
      "1. Drink plenty of fluids to stay hydrated.\n",
      "2. Dress in lightweight clothing.\n",
      "3. Use a light blanket if you feel chilled, until the chills end.\n",
      "4. Take acetaminophen (Tylenol, others) or ibuprofen (Advil, Motrin IB, others).\n",
      "5. Get medical help if the fever lasts more than five days in a row.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\Leinad\\Documents\\Tech_Villain\\Leinadpython\\firstaid\\model.hdf5 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('C:\\\\Users\\\\Leinad\\\\Documents\\\\Tech_Villain\\\\Leinadpython\\\\firstaid\\\\model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already trained the DNN model and loaded it as 'model'.\n",
    "# Also, you have prepared the test dataset as 'test_data' and 'test_labels'.\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "label_dict = {label: i for i, label in enumerate(labels)}\n",
    "test_labels_encoded = [[1 if label_dict[label] == i else 0 for i in range(len(labels))] for label in test_labels]\n",
    "\n",
    "# Preprocess the test data similar to the training data\n",
    "test_input = []\n",
    "for sentence in test_data:\n",
    "    bag = bag_of_words(sentence, words)\n",
    "    test_input.append(bag)\n",
    "\n",
    "# Convert test_input to a numpy array\n",
    "test_input = numpy.array(test_input)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(test_input)\n",
    "\n",
    "# Calculate the accuracy\n",
    "correct_predictions = 0\n",
    "total_predictions = len(test_labels)\n",
    "for i in range(total_predictions):\n",
    "    predicted_label_index = numpy.argmax(predictions[i])\n",
    "    true_label_index = numpy.argmax(test_labels_encoded[i])\n",
    "    if predicted_label_index == true_label_index:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# evaluation_result = model.evaluate(test_input, test_labels_encoded)\n",
    "# loss = evaluation_result[0]  # Extract the first element (loss value) from the evaluation result list\n",
    "# print(\"Loss: {:.4f}\".format(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, eval_data, train_labels, eval_labels = train_test_split(training, output, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(eval_data)\n",
    "\n",
    "# Convert the predictions to class labels (index with the highest probability)\n",
    "predicted_labels = [labels[prediction.argmax()] for prediction in predictions]\n",
    "\n",
    "# Calculate accuracy as the evaluation metric\n",
    "accuracy = accuracy_score([labels[label.argmax()] for label in eval_labels], predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9999999997368421\n",
      "Recall: 0.9999999997368421\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def calculate_tp_fp_fn(y_true, y_pred):\n",
    "    tp = np.sum(np.logical_and(y_true == 1, y_pred == 1))\n",
    "    fp = np.sum(np.logical_and(y_true == 0, y_pred == 1))\n",
    "    fn = np.sum(np.logical_and(y_true == 1, y_pred == 0))\n",
    "    return tp, fp, fn\n",
    "\n",
    "# Evaluate precision and recall\n",
    "def evaluate_precision_recall(y_true, y_pred):\n",
    "    tp, fp, fn = calculate_tp_fp_fn(y_true, y_pred)\n",
    "    precision = tp / (tp + fp + 1e-8)  # Add small epsilon to avoid division by zero\n",
    "    recall = tp / (tp + fn + 1e-8)     # Add small epsilon to avoid division by zero\n",
    "    return precision, recall\n",
    "\n",
    "# Assuming you already have the predictions and ground truth labels\n",
    "# predictions contains the predicted labels (converted to class indices)\n",
    "# eval_labels contains the ground truth labels (converted to class indices)\n",
    "\n",
    "# Convert predictions and eval_labels to binary format for multilabel evaluation\n",
    "y_pred_binary = np.zeros_like(predictions)\n",
    "y_pred_binary[np.arange(len(predictions)), predictions.argmax(axis=1)] = 1\n",
    "\n",
    "eval_labels_binary = np.zeros_like(eval_labels)\n",
    "eval_labels_binary[np.arange(len(eval_labels)), eval_labels.argmax(axis=1)] = 1\n",
    "\n",
    "# Evaluate precision and recall\n",
    "precision, recall = evaluate_precision_recall(eval_labels_binary, y_pred_binary)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
